# 并行编程

## GPU硬件模型

我们以nvidia-gpu为例，因为nvidia是这一领域的先行者。

![](https://modal-cdn.com/gpu-glossary/light-cuda-g80.svg)

其实"CUDA"一词除了被引申为我们常说的并行编程模型外，还可用于指代硬件架构，这种说法参见https://modal.com/gpu-glossary/device-hardware/cuda-device-architecture。gpu硬件的通用硬件模型可以这样表达：

* 每一个设备都由多个流式多处理器（streaming multiprocessors）构成

* 每个处理器由多个Cuda cores/Tensor cores构成

想找具体的例子，可以看tesla p100发布白皮书中的内容：https://images.nvidia.com/content/pdf/tesla/whitepaper/pascal-architecture-whitepaper.pdf

### SMs

gpu上运行推理任务，其实可以被看作是这样一个过程：SMs在运行大量的**流处理器汇编代码**，我们以H800（下图）为例——蓝色为内存，绿色为core，橙色为调度单元

![](https://modal-cdn.com/gpu-glossary/light-gh100-sm.svg)

以H800为例，它峰值功率为700w，132个流处理器，每个具有4个warp调度器，而每个调度器又能以32个线程并行地发送指令，所以一个SM的并行度是4*32=128，同时，一个SM的并发容量是2048，GPU使用极其高效的warp切换技术能够实现最高25万个任务并发的效果

<br>

### Core

core是组成流处理器的基本组件，包括两种类型：cuda-core和tensor-core

相对于gpu的core，我们一般更了解cpu的cpu，并可能会把它们联系到一起，事实上他们很不一样。相较于tensor-core，cpu的core和SM更像，因为他们都拥有寄存器可以暂存数据。

<br>

### SFU

special function unit。用来计算特殊数学元算的单元：比如exp,cos,sin



<br>

## loopy并行模型

### loopy软件架构

#### loopkernel

这个结构包含了生成代码所需要的全部信息

它包含了这些信息：

- Domains: 迭代空间的约束和迭代变量
- Instructions: 需要执行的计算操作
- Arguments: 输入和输出参数
- Temporaries: 计算过程中的临时变量
- Dependencies: 指令和迭代之间的关系
- Options: kernel的配置参数

![](/Users/wangjiajie/software/ClassNotebook/statics/loopkernel.png)

<br>

#### preprocess过程

- 类型推断: 变量和表达式的类型推断
- Common subexpression elimination (CSE): 识别并消除重复的表达式
- 依赖分析: 识别表达式之间的关系
- Domain transformation: 修改迭代空间

相关的功能在`__init__.py`的85行和210行进行导入

<br>

#### transformation系统

优化实际上是通过各类变换来达到的，这可以说是loopy。为此，loopy的核心代码中存在一个transformation系统，kernel被传递进管道系统中，经过一层层的优化，变成了最终被完整优化的kernel代码。

<img title="" src="../statics/transformation-sys.png" alt="" width="652">

<br>

#### expression系统...

其他模型细节参见https://deepwiki.com/inducer/loopy/1.1-architecture

<br>

### loopy并行模型

#### Inames&Domains

Inames代表Iteration name，Domains代表

#### 宏观优化技术

- **并行性映射 (Parallelism Mapping):** 通过 `lp.tag_inames`，你可以将 `loopy` 中的 `iname` (循环索引) 精确地映射到 CUDA 的 `blockIdx`, `threadIdx` (包括x,y,z维度) 以及 `warp` 相关的索引。这使得你可以精细控制计算如何在 GPU 的不同层级并行单元上执行。
  - 例如，`loopy/target/cuda.py` 中定义了如 `lp.CUDABlockIndexTag`, `lp.CUDAThreadIndexTag` 等。
- **内存层级优化 (Memory Hierarchy Optimization):**
  - **共享内存 (Shared Memory):** 你可以将数组标记为使用 `AddressSpace.LOCAL` (在 `loopy/kernel/data.py` 中定义)，`loopy` 的 CUDA 后端会将其转换为 `__shared__` 内存。通过 `lp.buffer_array` 等变换，你可以显式地控制哪些数据被加载到共享内存中，以及如何组织（例如，通过分块）。
  - **寄存器使用：** 通过循环展开、数据私有化 (`lp.privatize_array`) 等变换，可以增加数据在寄存器中的重用机会，减少对低速内存的访问。
  - **全局内存访问模式：** 变换如 `lp.split_iname` 后进行 `lp.tag_inames` 可以帮助实现合并的全局内存访问 (coalesced access)。`lp.add_prefetch` 可以用于显式的数据预取。
- **指令级优化 (Instruction-Level Parallelism - ILP):**
  - 循环展开 (`lp.unroll_iname`) 可以减少循环开销，并为编译器提供更大的指令调度窗口。
  - `loopy` 允许你指定数学运算的精度，或者使用特定的函数（如果后端支持）。
- **代码结构变换：**
  - 循环融合/分裂 (Fusion/Fission)
  - 循环交换 (Interchange)
  - 预计算 (`lp.precompute`)：将循环不变量或重复计算提前。

<br>

## cuda

<br>

## luminal
