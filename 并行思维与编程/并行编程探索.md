# 并行编程

## GPU硬件模型



<br>

## loopy并行模型

### loopy软件架构

#### loopkernel

这个结构包含了生成代码所需要的全部信息

它包含了这些信息：

- Domains: 迭代空间的约束和迭代变量
- Instructions: 需要执行的计算操作
- Arguments: 输入和输出参数
- Temporaries: 计算过程中的临时变量
- Dependencies: 指令和迭代之间的关系
- Options: kernel的配置参数

![](/Users/wangjiajie/software/ClassNotebook/statics/loopkernel.png)



<br>

### loopy中的并行优化技术

- **并行性映射 (Parallelism Mapping):** 通过 `lp.tag_inames`，你可以将 `loopy` 中的 `iname` (循环索引) 精确地映射到 CUDA 的 `blockIdx`, `threadIdx` (包括x,y,z维度) 以及 `warp` 相关的索引。这使得你可以精细控制计算如何在 GPU 的不同层级并行单元上执行。
  - 例如，`loopy/target/cuda.py` 中定义了如 `lp.CUDABlockIndexTag`, `lp.CUDAThreadIndexTag` 等。
- **内存层级优化 (Memory Hierarchy Optimization):**
  - **共享内存 (Shared Memory):** 你可以将数组标记为使用 `AddressSpace.LOCAL` (在 `loopy/kernel/data.py` 中定义)，`loopy` 的 CUDA 后端会将其转换为 `__shared__` 内存。通过 `lp.buffer_array` 等变换，你可以显式地控制哪些数据被加载到共享内存中，以及如何组织（例如，通过分块）。
  - **寄存器使用：** 通过循环展开、数据私有化 (`lp.privatize_array`) 等变换，可以增加数据在寄存器中的重用机会，减少对低速内存的访问。
  - **全局内存访问模式：** 变换如 `lp.split_iname` 后进行 `lp.tag_inames` 可以帮助实现合并的全局内存访问 (coalesced access)。`lp.add_prefetch` 可以用于显式的数据预取。
- **指令级优化 (Instruction-Level Parallelism - ILP):**
  - 循环展开 (`lp.unroll_iname`) 可以减少循环开销，并为编译器提供更大的指令调度窗口。
  - `loopy` 允许你指定数学运算的精度，或者使用特定的函数（如果后端支持）。
- **代码结构变换：**
  - 循环融合/分裂 (Fusion/Fission)
  - 循环交换 (Interchange)
  - 预计算 (`lp.precompute`)：将循环不变量或重复计算提前。

<br>

## cuda


